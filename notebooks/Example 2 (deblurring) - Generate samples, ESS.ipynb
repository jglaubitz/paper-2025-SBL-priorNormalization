{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Eliptical slice sampling (ESS) for prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# To start this notebook with more than one thread run \"export JULIA_NUM_THREADS=4\" in the terminal \n",
    "# before starting the jupyter notebook\n",
    "\n",
    "# Ensure that Julia was launched with an appropriate number of threads\n",
    "println(Threads.nthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import module. \n",
    "using Revise\n",
    "using PriorNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Distributions.loglikelihood in module Main conflicts with an existing identifier.\n",
      "WARNING: using StatsBase.loglikelihood in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "# Import packages \n",
    "using AdaptiveMCMC # for using adaptive MCMC sampling\n",
    "using ApproxFun # for approximating gammainvccdf by a Chbychev interpolant  \n",
    "using CairoMakie # for plots \n",
    "using Dates # to measure computational time \n",
    "using Distributions \n",
    "using EllipticalSliceSampling\n",
    "using FlexiMaps # for log-range  \n",
    "using ForwardDiff # for AD\n",
    "using JLD2 # for saving and loading results\n",
    "using LinearAlgebra # to represent the identity matrix as \"I\" \n",
    "using MCMCChains\n",
    "using Random # for generating random noise \n",
    "using StatsBase # for defining customized distributions \n",
    "using StatsFuns # for defining customized distributions \n",
    "using StatsPlots # for plotting \n",
    "using SparseArrays # for efficient storing of the forward operator \n",
    "using SpecialFunctions\n",
    "#using Turing # for setting up the model and sampling \n",
    "using Optim # for ML and MAP estimation \n",
    "using Plots: Plots, plot, plot!, scatter, scatter!, savefig, surface, surface!\n",
    "using ProgressMeter # to show progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare arguments.  \n",
    "nr_chains = 6 # number of chains to sample \n",
    "nr_samples_raw = 10^3 # number of samples \n",
    "thin = 10^0 # Thinning factor; only every thin-th sample is stored\n",
    "init = \"MAP\" # Initialization option: \"MAP\", \"prior\"\n",
    "nr_samples = Int64( nr_samples_raw/thin )\n",
    "\n",
    "# Tests: \n",
    "# nr_samples_raw = 10^3, thin = 10^0: 18s & 3s\n",
    "# nr_samples_raw = 10^4, thin = 10^0: 22s & 33s\n",
    "# nr_samples_raw = 10^5, thin = 10^1: 294 & 296\n",
    "# nr_samples_raw = 10^6, thin = 10^2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal deblurring problem: Define the data model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       "  1.0\n",
       " -2.4\n",
       "  2.8\n",
       " -0.6\n",
       " -0.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model parameters \n",
    "σ² = 0.03^2 # noise variance \n",
    "kernel_width = 0.02 # width of the Gaussian kernel\n",
    "N_dense = 1_000 # number of points for the dense model\n",
    "N_coarse = 128 # number of points for the coarse model\n",
    "tt = [0.17, 0.39, 0.48, 0.73, 0.83] # Positions of the increments\n",
    "dx = [1, -2.4, 2.8, -0.6, -0.8] # Values of the increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the piecewise constant signal. \n",
    "function signal(t; tt=[0.17, 0.39, 0.48, 0.73, 0.83], \n",
    "    dx = [1, -2.4, 2.8, -0.6, -0.8])\n",
    "    x = 0\n",
    "    Ij = findall(x -> x < t, tt)\n",
    "    if !isempty(Ij)\n",
    "        x = sum(dx[Ij])\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Any}:\n",
       "  3.74278937539227e-18\n",
       "  5.744144243534786e-18\n",
       "  8.79393927412621e-18\n",
       "  1.3429811599511571e-17\n",
       "  2.0459022030414613e-17\n",
       "  3.1090554911693094e-17\n",
       "  4.713037498942281e-17\n",
       "  7.126926866908596e-17\n",
       "  1.0750603997755944e-16\n",
       "  1.6176805186960793e-16\n",
       "  2.428187113838113e-16\n",
       "  3.6358103971191115e-16\n",
       "  5.430629429581705e-16\n",
       "  ⋮\n",
       "  2.653109939010615e-16\n",
       "  1.693119370541826e-16\n",
       "  1.0509846120628357e-16\n",
       "  6.233097419208321e-17\n",
       "  3.399747075949146e-17\n",
       "  1.535468383152762e-17\n",
       "  3.2021048354653674e-18\n",
       " -4.614439835542763e-18\n",
       " -9.541335133345305e-18\n",
       " -1.2547439067780209e-17\n",
       " -1.4280276203172293e-17\n",
       " -1.5171704985465577e-17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the dense data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_dense = (1:N_dense) / N_dense \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_dense, N_dense, 1), N_dense, N_dense)\n",
    "T = S'\n",
    "F_dense = (6.4/N_dense) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Generate the dense step signal and observations \n",
    "x_dense = signal.(t_dense) # signal values \n",
    "y_dense = F_dense * x_dense # observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the coarse data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_coarse = (1:N_coarse) / N_coarse \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_coarse, N_coarse, 1), N_coarse, N_coarse)\n",
    "T = S'\n",
    "F_coarse = (6.4/N_coarse) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Get the coarse grid and forward operator \n",
    "stride = 6 # use every stride-th point \n",
    "t_obs = t_coarse[1:stride:end]\n",
    "F_coarse = F_coarse[1:stride:end, :]\n",
    "\n",
    "# Find the nearest points in the dense grid\n",
    "m = length(t_obs)\n",
    "I_dense = zeros(Int, m)\n",
    "for j in 1:m\n",
    "    I_dense[j] = argmin(abs.(t_dense .- t_obs[j]))\n",
    "end\n",
    "     \n",
    "# Coarse data with added noise\n",
    "Random.seed!(123) # Setting the seed \n",
    "y_coarse = y_dense[I_dense] .+ sqrt(σ²)*randn(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invertible finite difference matrix\n",
    "aux = ones(N_coarse) * [-1.0, 1.0]'\n",
    "L = spzeros(Float64,N_coarse,N_coarse)\n",
    "L[2:end,:] = spdiagm(0=>-1*ones(N_coarse), 1=>ones(N_coarse))[1:N_coarse-1,1:N_coarse]\n",
    "L[1,1] = 1 \n",
    "\n",
    "# Change coordinates to promot sparsity in z = Lx\n",
    "FL = F_coarse / L # F_coarse * inv(L)\n",
    "\n",
    "# Whitening\n",
    "FL_w = (1/sqrt(σ²)) * FL\n",
    "y_w = (1/sqrt(σ²)) * y_coarse\n",
    "\n",
    "# Rename varables for simplicity \n",
    "F = FL_w \n",
    "y = y_w \n",
    "M, N = size(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model: $r=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012308"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 4 \n",
    "\n",
    "# Parameter of of generalized gamma hyper-prior \n",
    "r_range = [ 1.0, .5, -.5, -1.0 ]; \n",
    "β_range = [ 1.501, 3.0918, 2.0165, 1.0017 ];\n",
    "ϑ_range = [ 5*10^(-2), 5.9323*10^(-3), 1.2583*10^(-3), 1.2308*10^(-4) ];\n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Γinvccdf_cheb_extd (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval = -5..5\n",
    "# Create an array of functions\n",
    "if r > 0 \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5*erfc(τ/sqrt(2)) ), interval)\n",
    "else \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5 + 0.5*erf(τ/sqrt(2)) ), interval)\n",
    "end\n",
    "\n",
    "# Calculate the value and derivative at the boundaries\n",
    "Γinvccdf_val_left = Γinvccdf_cheb(interval.left)\n",
    "Γinvccdf_val_right = Γinvccdf_cheb(interval.right)\n",
    "\n",
    "Γinvccdf_deriv_left = ForwardDiff.derivative(Γinvccdf_cheb, interval.left)\n",
    "Γinvccdf_deriv_right = ForwardDiff.derivative(Γinvccdf_cheb, interval.right)\n",
    "\n",
    "# Define the extended function\n",
    "function Γinvccdf_cheb_extd(τ)\n",
    "    if τ < interval.left\n",
    "        return Γinvccdf_val_left + Γinvccdf_deriv_left * (τ - interval.left)\n",
    "    elseif τ > interval.right\n",
    "        return abs(Γinvccdf_val_right + Γinvccdf_deriv_right * (τ - interval.right))\n",
    "    else\n",
    "        return Γinvccdf_cheb(τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the posterior density \n",
    "function logpdf_likelihood(τ, u; F, y, r, β, ϑ, Φ::Function) \n",
    "\n",
    "    # Get z-value by using transport map \n",
    "    z = similar(u)\n",
    "    z = priorNormalizing_KR_inv_tu_fast( u, τ; r, β, ϑ, Φ )\n",
    "    \n",
    "    # Get log-posterior \n",
    "    logpdf = -0.5*norm(F*z-y)^2\n",
    "    \n",
    "    return logpdf\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loglikelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikelihood(ξ) = logpdf_likelihood(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ, Φ=Γinvccdf_cheb_extd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZeroMeanDiagNormal(\n",
       "dim: 256\n",
       "μ: Zeros(256)\n",
       "Σ: [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]\n",
       ")\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set-up standard normal prior \n",
    "prior = MvNormal(Diagonal(ones(2*N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate random samples from the standard normal prior \n",
    "priorNormalized_prior = Array{Float64}(undef, 2*N, nr_samples)\n",
    "τ_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "u_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains\n",
    "    priorNormalized_prior[1:2:end-1,j] .= τ_prior_samples[:,j]\n",
    "    priorNormalized_prior[2:2:end,j] .= u_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model4_mcmc_initMAP_ESS_priorNormalized_samples1000_thin1_chains6.jld2\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param_priorNormalized = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param = repeat([priorNormalized_MAP], nr_chains, 1)\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    filename_priorNormalized = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_ESS_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    init_param = repeat([priorNormalized_MAP], nr_chains, 1)\n",
    "    for j in 1:nr_chains \n",
    "        init_param[j] = priorNormalized_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_ESS_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from the prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.234"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize\n",
    "#init_param = vec(priorNormalized_MAP)\n",
    "nr_parameters = 2*N\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# ESS \n",
    "samples = Distributions.sample(\n",
    "    ESSModel(prior, loglikelihood), \n",
    "    EllipticalSliceSampling.ESS(), \n",
    "    MCMCThreads(), \n",
    "    nr_samples_raw, \n",
    "    nr_chains; \n",
    "    initial_params=init_param, \n",
    "    progress=false\n",
    ")\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_priorNormalized = Dates.value(wall_duration_ms) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into proper MCMC chain \n",
    "chn_values = zeros(Float64, nr_samples, 2*N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains \n",
    "    chn_aux = samples[j] # jth chain\n",
    "    for n in 1:nr_samples  \n",
    "        chn_values[n, :, j] = chn_aux[n]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_τ = [string(\"τ[\", i, \"]\") for i in 1:N ]\n",
    "param_names_u = [string(\"u[\", i, \"]\") for i in 1:N ]\n",
    "\n",
    "# Interleave τ and u names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_τ\n",
    "param_names[2:2:end] .= param_names_u\n",
    "\n",
    "# Create the Chains object\n",
    "chn_priorNormalized = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_priorNormalized chn_priorNormalized wall_duration_priorNormalized\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_priorNormalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
