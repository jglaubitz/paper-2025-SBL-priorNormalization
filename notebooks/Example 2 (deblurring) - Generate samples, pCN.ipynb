{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Eliptical slice sampling (ESS) for prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# To start this notebook with more than one thread run \"export JULIA_NUM_THREADS=4\" in the terminal \n",
    "# before starting the jupyter notebook\n",
    "\n",
    "# Ensure that Julia was launched with an appropriate number of threads\n",
    "println(Threads.nthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import module. \n",
    "using Revise\n",
    "using PriorNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "using AdaptiveMCMC # for using adaptive MCMC sampling\n",
    "using ApproxFun # for approximating gammainvccdf by a Chbychev interpolant  \n",
    "using CairoMakie # for plots \n",
    "using Dates # to measure computational time \n",
    "using Distributions \n",
    "using FlexiMaps # for log-range  \n",
    "using ForwardDiff # for AD\n",
    "using JLD2 # for saving and loading results\n",
    "using LinearAlgebra # to represent the identity matrix as \"I\" \n",
    "using MCMCChains\n",
    "using Random # for generating random noise \n",
    "using StatsBase # for defining customized distributions \n",
    "using StatsFuns # for defining customized distributions \n",
    "using StatsPlots # for plotting \n",
    "using SparseArrays # for efficient storing of the forward operator \n",
    "using SpecialFunctions\n",
    "using Turing # for setting up the model and sampling \n",
    "using Optim # for ML and MAP estimation \n",
    "using Plots: Plots, plot, plot!, scatter, scatter!, savefig, surface, surface!\n",
    "using ProgressMeter # to show progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare arguments.  \n",
    "nr_chains = 6 # number of chains to sample \n",
    "nr_samples_raw = 10^5 # number of samples \n",
    "thin = 10^1 # Thinning factor; only every thin-th sample is stored\n",
    "init = \"prior\" # Initialization option: \"MAP\", \"prior\"\n",
    "nr_samples = Int64( nr_samples_raw/thin )\n",
    "step_size = 0.02 # pCN step size \n",
    "\n",
    "# Tests for step_size = 0.01: \n",
    "# nr_samples_raw = 10^4, thin = 10^0: 3s, 37% & 5s, 58%\n",
    "# nr_samples_raw = 10^5, thin = 10^1: 24s, 37% & 36s, 39%\n",
    "# nr_samples_raw = 10^6, thin = 10^2: \n",
    "\n",
    "# Tests for step_size = 0.02: \n",
    "# nr_samples_raw = 10^4, thin = 10^0: 5s, 16% & 5s, 27%\n",
    "# nr_samples_raw = 10^5, thin = 10^1: 28s, 15% & 23s, 17%\n",
    "# nr_samples_raw = 10^6, thin = 10^2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal deblurring problem: Define the data model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       "  1.0\n",
       " -2.4\n",
       "  2.8\n",
       " -0.6\n",
       " -0.8"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model parameters \n",
    "σ² = 0.03^2 # noise variance \n",
    "kernel_width = 0.02 # width of the Gaussian kernel\n",
    "N_dense = 1_000 # number of points for the dense model\n",
    "N_coarse = 128 # number of points for the coarse model\n",
    "tt = [0.17, 0.39, 0.48, 0.73, 0.83] # Positions of the increments\n",
    "dx = [1, -2.4, 2.8, -0.6, -0.8] # Values of the increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal (generic function with 1 method)"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the piecewise constant signal. \n",
    "function signal(t; tt=[0.17, 0.39, 0.48, 0.73, 0.83], \n",
    "    dx = [1, -2.4, 2.8, -0.6, -0.8])\n",
    "    x = 0\n",
    "    Ij = findall(x -> x < t, tt)\n",
    "    if !isempty(Ij)\n",
    "        x = sum(dx[Ij])\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Any}:\n",
       "  3.74278937539227e-18\n",
       "  5.744144243534786e-18\n",
       "  8.79393927412621e-18\n",
       "  1.3429811599511571e-17\n",
       "  2.0459022030414613e-17\n",
       "  3.1090554911693094e-17\n",
       "  4.713037498942281e-17\n",
       "  7.126926866908596e-17\n",
       "  1.0750603997755944e-16\n",
       "  1.6176805186960793e-16\n",
       "  2.428187113838113e-16\n",
       "  3.6358103971191115e-16\n",
       "  5.430629429581705e-16\n",
       "  ⋮\n",
       "  2.653109939010615e-16\n",
       "  1.693119370541826e-16\n",
       "  1.0509846120628357e-16\n",
       "  6.233097419208321e-17\n",
       "  3.399747075949146e-17\n",
       "  1.535468383152762e-17\n",
       "  3.2021048354653674e-18\n",
       " -4.614439835542763e-18\n",
       " -9.541335133345305e-18\n",
       " -1.2547439067780209e-17\n",
       " -1.4280276203172293e-17\n",
       " -1.5171704985465577e-17"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the dense data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_dense = (1:N_dense) / N_dense \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_dense, N_dense, 1), N_dense, N_dense)\n",
    "T = S'\n",
    "F_dense = (6.4/N_dense) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Generate the dense step signal and observations \n",
    "x_dense = signal.(t_dense) # signal values \n",
    "y_dense = F_dense * x_dense # observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the coarse data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_coarse = (1:N_coarse) / N_coarse \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_coarse, N_coarse, 1), N_coarse, N_coarse)\n",
    "T = S'\n",
    "F_coarse = (6.4/N_coarse) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Get the coarse grid and forward operator \n",
    "stride = 6 # use every stride-th point \n",
    "t_obs = t_coarse[1:stride:end]\n",
    "F_coarse = F_coarse[1:stride:end, :]\n",
    "\n",
    "# Find the nearest points in the dense grid\n",
    "m = length(t_obs)\n",
    "I_dense = zeros(Int, m)\n",
    "for j in 1:m\n",
    "    I_dense[j] = argmin(abs.(t_dense .- t_obs[j]))\n",
    "end\n",
    "     \n",
    "# Coarse data with added noise\n",
    "Random.seed!(123) # Setting the seed \n",
    "y_coarse = y_dense[I_dense] .+ sqrt(σ²)*randn(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 128)"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invertible finite difference matrix\n",
    "aux = ones(N_coarse) * [-1.0, 1.0]'\n",
    "L = spzeros(Float64,N_coarse,N_coarse)\n",
    "L[2:end,:] = spdiagm(0=>-1*ones(N_coarse), 1=>ones(N_coarse))[1:N_coarse-1,1:N_coarse]\n",
    "L[1,1] = 1 \n",
    "\n",
    "# Change coordinates to promot sparsity in z = Lx\n",
    "FL = F_coarse / L # F_coarse * inv(L)\n",
    "\n",
    "# Whitening\n",
    "FL_w = (1/sqrt(σ²)) * FL\n",
    "y_w = (1/sqrt(σ²)) * y_coarse\n",
    "\n",
    "# Rename varables for simplicity \n",
    "F = FL_w \n",
    "y = y_w \n",
    "M, N = size(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model: $r=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012308"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 4 \n",
    "\n",
    "# Parameter of of generalized gamma hyper-prior \n",
    "r_range = [ 1.0, .5, -.5, -1.0 ]; \n",
    "β_range = [ 1.501, 3.0918, 2.0165, 1.0017 ];\n",
    "ϑ_range = [ 5*10^(-2), 5.9323*10^(-3), 1.2583*10^(-3), 1.2308*10^(-4) ];\n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Γinvccdf_cheb_extd (generic function with 1 method)"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval = -5..5\n",
    "# Create an array of functions\n",
    "if r > 0 \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5*erfc(τ/sqrt(2)) ), interval)\n",
    "else \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5 + 0.5*erf(τ/sqrt(2)) ), interval)\n",
    "end\n",
    "\n",
    "# Calculate the value and derivative at the boundaries\n",
    "Γinvccdf_val_left = Γinvccdf_cheb(interval.left)\n",
    "Γinvccdf_val_right = Γinvccdf_cheb(interval.right)\n",
    "\n",
    "Γinvccdf_deriv_left = ForwardDiff.derivative(Γinvccdf_cheb, interval.left)\n",
    "Γinvccdf_deriv_right = ForwardDiff.derivative(Γinvccdf_cheb, interval.right)\n",
    "\n",
    "# Define the extended function\n",
    "function Γinvccdf_cheb_extd(τ)\n",
    "    if τ < interval.left\n",
    "        return Γinvccdf_val_left + Γinvccdf_deriv_left * (τ - interval.left)\n",
    "    elseif τ > interval.right\n",
    "        return abs(Γinvccdf_val_right + Γinvccdf_deriv_right * (τ - interval.right))\n",
    "    else\n",
    "        return Γinvccdf_cheb(τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the posterior density \n",
    "function logpdf_likelihood(τ, u; F, y, r, β, ϑ, Φ::Function) \n",
    "\n",
    "    # Get z-value by using transport map \n",
    "    z = similar(u)\n",
    "    z = priorNormalizing_KR_inv_tu_fast( u, τ; r, β, ϑ, Φ )\n",
    "    \n",
    "    # Get log-posterior \n",
    "    logpdf = -0.5*norm(F*z-y)^2\n",
    "    \n",
    "    return logpdf\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(ξ) = -logpdf_likelihood(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ, Φ=Γinvccdf_cheb_extd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate random samples from the standard normal prior \n",
    "priorNormalized_prior = Array{Float64}(undef, 2*N, nr_samples)\n",
    "τ_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "u_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains\n",
    "    priorNormalized_prior[1:2:end,j] .= τ_prior_samples[:,j]\n",
    "    priorNormalized_prior[2:2:end,j] .= u_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model4_mcmc_initPrior_pCN_priorNormalized_samples100000_thin10_chains6.jld2\""
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param[:,j] = priorNormalized_MAP[:]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results  \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_pCN_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param[:,j] = priorNormalized_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_pCN_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pCN sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_acc_prob (generic function with 1 method)"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the logarithm of the acceptance probability of the pCN algorithm\n",
    "function log_acc_prob(τ_old, u_old, τ_prop, u_prop) \n",
    "    N = length(τ_old)\n",
    "\n",
    "    ξ_old = zeros(2*N) \n",
    "    ξ_old[1:2:end-1] = τ_old\n",
    "    ξ_old[2:2:end] = u_old\n",
    "    \n",
    "    ξ_prop = zeros(2*N) \n",
    "    ξ_prop[1:2:end-1] = τ_prop\n",
    "    ξ_prop[2:2:end] = u_prop\n",
    "    \n",
    "    log_α = min(0, log_likelihood(ξ_old) - log_likelihood(ξ_prop) )\n",
    "    \n",
    "    return log_α\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pCN_sampler (generic function with 1 method)"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Gibbs sampling function\n",
    "function pCN_sampler(τ_init, u_init, step_size, iterations)\n",
    "    N = length(τ_init)\n",
    "    step_size_param = sqrt( 1 - step_size^2 )\n",
    "    acc_counter = 0\n",
    "    \n",
    "    # Preallocate space to store samples\n",
    "    samples_τ = zeros(iterations, N)\n",
    "    samples_u = zeros(iterations, N)\n",
    "\n",
    "    # Initialize values \n",
    "    τ_old = τ_init\n",
    "    u_old = u_init\n",
    "    τ_prop = zeros(N)\n",
    "    u_prop = zeros(N)\n",
    "    \n",
    "    # Store samples\n",
    "    samples_τ[1, :] = τ_old\n",
    "    samples_u[1, :] = u_old\n",
    "    \n",
    "    for i in 2:iterations\n",
    "        \n",
    "        # Step 1: Proposal \n",
    "        v1 = rand(Normal(0,1), N)\n",
    "        τ_prop = step_size_param*τ_old + step_size*v1\n",
    "        v2 = rand(Normal(0,1), N)\n",
    "        u_prop = step_size_param*u_old + step_size*v2\n",
    "        \n",
    "        # Step 2: MH accept/reject\n",
    "        z = rand(1)\n",
    "        log_α = log_acc_prob(τ_old, u_old, τ_prop, u_prop)\n",
    "        if log(z[1]) <= minimum([0, log_α])\n",
    "            τ_old = τ_prop\n",
    "            u_old = u_prop \n",
    "            acc_counter += 1\n",
    "        end\n",
    "            \n",
    "        # Store samples\n",
    "        samples_τ[i, :] = τ_old\n",
    "        samples_u[i, :] = u_old\n",
    "    end\n",
    "\n",
    "    acc_rate = acc_counter/(iterations-1)\n",
    "    \n",
    "    return samples_τ, samples_u, acc_rate\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:23\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "Tau_init = zeros(Float64, N, nr_chains)\n",
    "U_init = zeros(Float64, N, nr_chains)\n",
    "Tau = zeros(Float64, nr_samples_raw, N, nr_chains)\n",
    "U = zeros(Float64, nr_samples_raw, N, nr_chains)\n",
    "acc_rates = zeros(Float64, nr_chains)\n",
    "chn_values = zeros(Float64, nr_samples, 2*N, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains   \n",
    "    \n",
    "    # Initilization \n",
    "    Tau_init[:,j] = init_param[1:2:end-1,j]\n",
    "    U_init[:,j] = init_param[2:2:end,j]\n",
    "    \n",
    "    # Generate samples\n",
    "    Tau[:,:,j], U[:,:,j], acc_rates[j] = pCN_sampler(\n",
    "        Tau_init[:,j], \n",
    "        U_init[:,j], \n",
    "        step_size, \n",
    "        nr_samples_raw\n",
    "    )\n",
    "    \n",
    "    # Store values \n",
    "    chn_values[:,1:2:end-1,j] = Tau[1:thin:nr_samples_raw,:,j]\n",
    "    chn_values[:,2:2:end,j] = U[1:thin:nr_samples_raw,:,j]\n",
    "end\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_priorNormalized = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (τ[1], u[1], τ[2], u[2], ...)\n",
    "param_names_τ = [string(\"τ[\", i, \"]\") for i in 1:N ]\n",
    "param_names_u = [string(\"u[\", i, \"]\") for i in 1:N ]\n",
    "\n",
    "# Interleave θ and z names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end-1] .= param_names_τ\n",
    "param_names[2:2:end] .= param_names_u\n",
    "\n",
    "# Create the Chains object\n",
    "chn_priorNormalized = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc() # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.909\n",
      "0.1758634253009197\n",
      "[0.18977189771897718, 0.18172181721817218, 0.15973159731597317, 0.18051180511805118, 0.15302153021530215, 0.1904219042190422]\n"
     ]
    }
   ],
   "source": [
    "mean_acc_rate = mean(acc_rates)\n",
    "\n",
    "println(wall_duration_priorNormalized) \n",
    "println(mean_acc_rate) \n",
    "println(acc_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_priorNormalized chn_priorNormalized wall_duration_priorNormalized mean_acc_rate\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_priorNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
