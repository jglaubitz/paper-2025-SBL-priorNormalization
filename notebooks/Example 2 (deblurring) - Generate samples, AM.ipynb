{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Generate and save samples for different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# To start this notebook with more than one thread run \"export JULIA_NUM_THREADS=4\" in the terminal \n",
    "# before starting the jupyter notebook\n",
    "\n",
    "# Ensure that Julia was launched with an appropriate number of threads\n",
    "println(Threads.nthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import module. \n",
    "using Revise\n",
    "using PriorNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "using AdaptiveMCMC # for using adaptive MCMC sampling\n",
    "using ApproxFun # for approximating gammainvccdf by a Chbychev interpolant  \n",
    "using CairoMakie # for plots \n",
    "using Dates # to measure computational time \n",
    "using Distributions\n",
    "using JLD2 # for saving and loading results\n",
    "using FlexiMaps # for log-range  \n",
    "using ForwardDiff # for AD\n",
    "using LinearAlgebra # to represent the identity matrix as \"I\" \n",
    "using Random # for generating random noise \n",
    "using StatsBase # for defining customized distributions \n",
    "using StatsFuns # for defining customized distributions \n",
    "using StatsPlots # for plotting \n",
    "using SparseArrays # for efficient storing of the forward operator \n",
    "using SpecialFunctions\n",
    "using Turing # for setting up the model and sampling \n",
    "using Optim # for ML and MAP estimation \n",
    "using Plots: Plots, plot, plot!, scatter, scatter!, savefig, surface, surface!\n",
    "using ProgressMeter # to show progress "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling parameters\n",
    "\n",
    "We use an adaptive RWMH samples. \n",
    "See https://mvihola.github.io/docs/AdaptiveMCMC.jl/ or https://github.com/mvihola/AdaptiveMCMC.jl for details. \n",
    "We can us the following different algorithm options (see https://mvihola.github.io/docs/AdaptiveMCMC.jl/adapt/#Adaptation-state):\n",
    "\n",
    "    :am = AdaptiveMetropolis\n",
    "    :ram = RobustAdaptiveMetropolis\n",
    "    :asm = AdaptiveScalingMetropolis\n",
    "    :aswam = AdaptiveScalingWithinAdaptiveMetropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare arguments.  \n",
    "nr_chains = 6 # number of chains to sample \n",
    "nr_samples_raw = 10^7 # number of samples \n",
    "thin = 10^3 # Thinning factor; only every thin-th sample is stored\n",
    "progress = false # show progress?\n",
    "init = \"prior\" # Initialization option: \"MAP\", \"prior\"\n",
    "\n",
    "# Tests: \n",
    "# nr_samples_raw = 10^5, thin = 10^1: \n",
    "# nr_samples_raw = 10^6, thin = 10^1, 10^2: \n",
    "# nr_samples_raw = 10^7, thin = 10^2, 10^3: \n",
    "# nr_samples_raw = 10^8, thin = 10^4:  \n",
    "\n",
    "burn_in_raw = 0 #Int64(ceil(nr_samples_raw/10)) # Burn-in length of 10% \n",
    "nr_samples = Int64( nr_samples_raw/thin )\n",
    "burn_in = 0 #Int64(ceil(nr_samples/10)) # Burn-in length of 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal deblurring problem: Define the data model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model parameters \n",
    "σ² = 0.03^2 # noise variance \n",
    "kernel_width = 0.02 # width of the Gaussian kernel\n",
    "N_dense = 1_000 # number of points for the dense model\n",
    "N_coarse = 128 # number of points for the coarse model\n",
    "tt = [0.17, 0.39, 0.48, 0.73, 0.83] # Positions of the increments\n",
    "dx = [1, -2.4, 2.8, -0.6, -0.8] # Values of the increments\n",
    "Random.seed!(123) # Setting the random seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the piecewise constant signal. \n",
    "function signal(t; tt=[0.17, 0.39, 0.48, 0.73, 0.83], \n",
    "    dx = [1, -2.4, 2.8, -0.6, -0.8])\n",
    "    x = 0\n",
    "    Ij = findall(x -> x < t, tt)\n",
    "    if !isempty(Ij)\n",
    "        x = sum(dx[Ij])\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Any}:\n",
       "  3.74278937539227e-18\n",
       "  5.744144243534786e-18\n",
       "  8.79393927412621e-18\n",
       "  1.3429811599511571e-17\n",
       "  2.0459022030414613e-17\n",
       "  3.1090554911693094e-17\n",
       "  4.713037498942281e-17\n",
       "  7.126926866908596e-17\n",
       "  1.0750603997755944e-16\n",
       "  1.6176805186960793e-16\n",
       "  ⋮\n",
       "  6.233097419208321e-17\n",
       "  3.399747075949146e-17\n",
       "  1.535468383152762e-17\n",
       "  3.2021048354653674e-18\n",
       " -4.614439835542763e-18\n",
       " -9.541335133345305e-18\n",
       " -1.2547439067780209e-17\n",
       " -1.4280276203172293e-17\n",
       " -1.5171704985465577e-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the dense data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_dense = (1:N_dense) / N_dense \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_dense, N_dense, 1), N_dense, N_dense)\n",
    "T = S'\n",
    "F_dense = (6.4/N_dense) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Generate the dense step signal and observations \n",
    "x_dense = signal.(t_dense) # signal values \n",
    "y_dense = F_dense * x_dense # observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the coarse data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_coarse = (1:N_coarse) / N_coarse \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_coarse, N_coarse, 1), N_coarse, N_coarse)\n",
    "T = S'\n",
    "F_coarse = (6.4/N_coarse) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Get the coarse grid and forward operator \n",
    "stride = 6 # use every stride-th point \n",
    "t_obs = t_coarse[1:stride:end]\n",
    "F_coarse = F_coarse[1:stride:end, :]\n",
    "\n",
    "# Find the nearest points in the dense grid\n",
    "m = length(t_obs)\n",
    "I_dense = zeros(Int, m)\n",
    "for j in 1:m\n",
    "    I_dense[j] = argmin(abs.(t_dense .- t_obs[j]))\n",
    "end\n",
    "     \n",
    "# Coarse data with added noise\n",
    "Random.seed!(123) # Setting the seed \n",
    "y_coarse = y_dense[I_dense] .+ sqrt(σ²)*randn(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 128)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Invertible finite difference matrix\n",
    "aux = ones(N_coarse) * [-1.0, 1.0]'\n",
    "L = spzeros(Float64,N_coarse,N_coarse)\n",
    "L[2:end,:] = spdiagm(0=>-1*ones(N_coarse), 1=>ones(N_coarse))[1:N_coarse-1,1:N_coarse]\n",
    "L[1,1] = 1 \n",
    "\n",
    "# Change coordinates to promot sparsity in z = Lx\n",
    "FL = F_coarse / L # F_coarse * inv(L)\n",
    "\n",
    "# Whitening\n",
    "FL_w = (1/sqrt(σ²)) * FL\n",
    "y_w = (1/sqrt(σ²)) * y_coarse\n",
    "\n",
    "# Rename varables for simplicity \n",
    "F = FL_w \n",
    "y = y_w \n",
    "M, N = size(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic models for the original and prior-normalized problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter of of generalized gamma hyper-prior \n",
    "r_range = [ 1.0, .5, -.5, -1.0 ]; \n",
    "β_range = [ 1.501, 3.0918, 2.0165, 1.0017 ];\n",
    "ϑ_range = [ 5*10^(-2), 5.9323*10^(-3), 1.2583*10^(-3), 1.2308*10^(-4) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_original (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the log-posterior density \n",
    "function logpdf_original(θ, z; F, y, r, β, ϑ)    \n",
    "    if any(θ .<= 0) # any non-positive element? \n",
    "        logpdf = -Inf \n",
    "    else\n",
    "        logpdf = -0.5*norm(F*z-y)^2 - \n",
    "            0.5*sum( z.^2 ./ θ ) - \n",
    "            sum( (θ/ϑ).^r ) + \n",
    "            (r*β-1.5)*sum( log.(θ) )\n",
    "    end\n",
    "    \n",
    "    return logpdf\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_priorNormalized (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the posterior density \n",
    "function logpdf_priorNormalized(τ, u; F, y, r, β, ϑ, Φ::Function) \n",
    "\n",
    "    # Get z-value by using transport map \n",
    "    z = similar(u)\n",
    "    z = priorNormalizing_KR_inv_tu_fast( u, τ; r, β, ϑ, Φ )\n",
    "    \n",
    "    # Get log-posterior \n",
    "    logpdf = -0.5*sum( u.^2 + τ.^2 ) -0.5*norm(F*z-y)^2\n",
    "    \n",
    "    return logpdf\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the model: $r=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05000000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 1  \n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Γinvccdf_cheb_extd (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interval = -5..5\n",
    "# Create an array of functions\n",
    "if r > 0 \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5*erfc(τ/sqrt(2)) ), interval)\n",
    "else \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5 + 0.5*erf(τ/sqrt(2)) ), interval)\n",
    "end\n",
    "\n",
    "# Calculate the value and derivative at the boundaries\n",
    "Γinvccdf_val_left = Γinvccdf_cheb(interval.left)\n",
    "Γinvccdf_val_right = Γinvccdf_cheb(interval.right)\n",
    "\n",
    "Γinvccdf_deriv_left = ForwardDiff.derivative(Γinvccdf_cheb, interval.left)\n",
    "Γinvccdf_deriv_right = ForwardDiff.derivative(Γinvccdf_cheb, interval.right)\n",
    "\n",
    "# Define the extended function\n",
    "function Γinvccdf_cheb_extd(τ)\n",
    "    if τ < interval.left\n",
    "        return Γinvccdf_val_left + Γinvccdf_deriv_left * (τ - interval.left)\n",
    "    elseif τ > interval.right\n",
    "        return abs(Γinvccdf_val_right + Γinvccdf_deriv_right * (τ - interval.right))\n",
    "    else\n",
    "        return Γinvccdf_cheb(τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_priorNormalized (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change definition and define negative log-PDF\n",
    "logpdf_original(ξ) = logpdf_original(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ\n",
    ")\n",
    "\n",
    "# Change definition and define negative log-PDF\n",
    "logpdf_priorNormalized(ξ) = logpdf_priorNormalized(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ, Φ=Γinvccdf_cheb_extd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the original posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_original.jld2\" θ_MAP z_MAP x_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "original_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "original_MAP[1:2:end] .= θ_MAP\n",
    "original_MAP[2:2:end] .= z_MAP\n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genrate random samples from the original prior \n",
    "\n",
    "original_prior = Array{Float64}(undef, 2*N, nr_chains)\n",
    "# Generate θ-samples from the gamma distribution\n",
    "θ_prior_samples = rand(Gamma(β,1), N, nr_chains)\n",
    "# Transform them into samples of the generalized gamma distribution \n",
    "θ_prior_samples = ϑ * θ_prior_samples.^(1/r)\n",
    "\n",
    "# Generate z-samples from the conditional Gaussian prior \n",
    "z_prior_samples = Array{Float64}(undef, N, nr_chains)\n",
    "# Loop over each chain and each sample to generate the normal samples\n",
    "for j in 1:nr_chains\n",
    "    for n in 1:N\n",
    "        # Standard deviation is sqrt(θ_prior_samples[i, j])\n",
    "        σ = sqrt(θ_prior_samples[n, j])\n",
    "        z_prior_samples[n, j] = rand(Normal(0, σ))\n",
    "    end\n",
    "    original_prior[1:2:end,j] .= θ_prior_samples[:,j]\n",
    "    original_prior[2:2:end,j] .= z_prior_samples[:,j]\n",
    "end\n",
    "\n",
    "\n",
    "## Genrate random samples from the standard normal prior \n",
    "priorNormalized_prior = Array{Float64}(undef, 2*N, nr_samples)\n",
    "τ_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "u_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains\n",
    "    priorNormalized_prior[1:2:end,j] .= τ_prior_samples[:,j]\n",
    "    priorNormalized_prior[2:2:end,j] .= u_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model1_mcmc_initPrior_AM_priorNormalized_samples10000000_thin1000_chains6.jld2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param_original = Array{Float64}(undef, 2*N, nr_chains)\n",
    "init_param_priorNormalized = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_MAP[:]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_MAP[:]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_prior[:,j]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the original posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:38\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works\n",
    "\n",
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains   \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_original[:,j], \n",
    "        logpdf_original, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_original = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_θ = [string(\"θ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_z = [string(\"z[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave θ and z names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_θ\n",
    "param_names[2:2:end] .= param_names_z\n",
    "\n",
    "# Create the Chains object\n",
    "chn_original = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_original chn_original wall_duration_original\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:16:42\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works \n",
    "\n",
    "# Initialize\n",
    "init_param = vec(priorNormalized_MAP)\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains \n",
    "    \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_priorNormalized[:,j], \n",
    "        logpdf_priorNormalized, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter?\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "    \n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_priorNormalized = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_τ = [string(\"τ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_u = [string(\"u[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave τ and u names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_τ\n",
    "param_names[2:2:end] .= param_names_u\n",
    "\n",
    "# Create the Chains object\n",
    "chn_priorNormalized = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_priorNormalized chn_priorNormalized wall_duration_priorNormalized\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_priorNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the model: $r=1/2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0059323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 2 \n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Γinvccdf_cheb_extd (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interval = -5..5\n",
    "# Create an array of functions\n",
    "if r > 0 \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5*erfc(τ/sqrt(2)) ), interval)\n",
    "else \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5 + 0.5*erf(τ/sqrt(2)) ), interval)\n",
    "end\n",
    "\n",
    "# Calculate the value and derivative at the boundaries\n",
    "Γinvccdf_val_left = Γinvccdf_cheb(interval.left)\n",
    "Γinvccdf_val_right = Γinvccdf_cheb(interval.right)\n",
    "\n",
    "Γinvccdf_deriv_left = ForwardDiff.derivative(Γinvccdf_cheb, interval.left)\n",
    "Γinvccdf_deriv_right = ForwardDiff.derivative(Γinvccdf_cheb, interval.right)\n",
    "\n",
    "# Define the extended function\n",
    "function Γinvccdf_cheb_extd(τ)\n",
    "    if τ < interval.left\n",
    "        return Γinvccdf_val_left + Γinvccdf_deriv_left * (τ - interval.left)\n",
    "    elseif τ > interval.right\n",
    "        return abs(Γinvccdf_val_right + Γinvccdf_deriv_right * (τ - interval.right))\n",
    "    else\n",
    "        return Γinvccdf_cheb(τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_priorNormalized (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change definition and define negative log-PDF\n",
    "logpdf_original(ξ) = logpdf_original(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ\n",
    ")\n",
    "\n",
    "# Change definition and define negative log-PDF\n",
    "logpdf_priorNormalized(ξ) = logpdf_priorNormalized(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ, Φ=Γinvccdf_cheb_extd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the original posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_original.jld2\" θ_MAP z_MAP x_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "original_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "original_MAP[1:2:end] .= θ_MAP\n",
    "original_MAP[2:2:end] .= z_MAP\n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genrate random samples from the original prior \n",
    "\n",
    "original_prior = Array{Float64}(undef, 2*N, nr_chains)\n",
    "# Generate θ-samples from the gamma distribution\n",
    "θ_prior_samples = rand(Gamma(β,1), N, nr_chains)\n",
    "# Transform them into samples of the generalized gamma distribution \n",
    "θ_prior_samples = ϑ * θ_prior_samples.^(1/r)\n",
    "\n",
    "# Generate z-samples from the conditional Gaussian prior \n",
    "z_prior_samples = Array{Float64}(undef, N, nr_chains)\n",
    "# Loop over each chain and each sample to generate the normal samples\n",
    "for j in 1:nr_chains\n",
    "    for n in 1:N\n",
    "        # Standard deviation is sqrt(θ_prior_samples[i, j])\n",
    "        σ = sqrt(θ_prior_samples[n, j])\n",
    "        z_prior_samples[n, j] = rand(Normal(0, σ))\n",
    "    end\n",
    "    original_prior[1:2:end,j] .= θ_prior_samples[:,j]\n",
    "    original_prior[2:2:end,j] .= z_prior_samples[:,j]\n",
    "end\n",
    "\n",
    "\n",
    "## Genrate random samples from the standard normal prior \n",
    "priorNormalized_prior = Array{Float64}(undef, 2*N, nr_samples)\n",
    "τ_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "u_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains\n",
    "    priorNormalized_prior[1:2:end,j] .= τ_prior_samples[:,j]\n",
    "    priorNormalized_prior[2:2:end,j] .= u_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model2_mcmc_initPrior_AM_priorNormalized_samples10000000_thin1000_chains6.jld2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param_original = Array{Float64}(undef, 2*N, nr_chains)\n",
    "init_param_priorNormalized = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_MAP[:]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_MAP[:]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_prior[:,j]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the original posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:06\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works\n",
    "\n",
    "# Initialize\n",
    "init_param = original_MAP\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains   \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_original[:,j], \n",
    "        logpdf_original, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_original = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_θ = [string(\"θ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_z = [string(\"z[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave θ and z names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_θ\n",
    "param_names[2:2:end] .= param_names_z\n",
    "\n",
    "# Create the Chains object\n",
    "chn_original = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_original chn_original wall_duration_original\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:12:25\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works \n",
    "\n",
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains \n",
    "    \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_priorNormalized[:,j], \n",
    "        logpdf_priorNormalized, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter?\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "    \n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_priorNormalized = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_τ = [string(\"τ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_u = [string(\"u[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave τ and u names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_τ\n",
    "param_names[2:2:end] .= param_names_u\n",
    "\n",
    "# Create the Chains object\n",
    "chn_priorNormalized = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_priorNormalized chn_priorNormalized wall_duration_priorNormalized\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_priorNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the model: $r=-1/2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012583"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 3 \n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Γinvccdf_cheb_extd (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interval = -5..5\n",
    "# Create an array of functions\n",
    "if r > 0 \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5*erfc(τ/sqrt(2)) ), interval)\n",
    "else \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5 + 0.5*erf(τ/sqrt(2)) ), interval)\n",
    "end\n",
    "\n",
    "# Calculate the value and derivative at the boundaries\n",
    "Γinvccdf_val_left = Γinvccdf_cheb(interval.left)\n",
    "Γinvccdf_val_right = Γinvccdf_cheb(interval.right)\n",
    "\n",
    "Γinvccdf_deriv_left = ForwardDiff.derivative(Γinvccdf_cheb, interval.left)\n",
    "Γinvccdf_deriv_right = ForwardDiff.derivative(Γinvccdf_cheb, interval.right)\n",
    "\n",
    "# Define the extended function\n",
    "function Γinvccdf_cheb_extd(τ)\n",
    "    if τ < interval.left\n",
    "        return Γinvccdf_val_left + Γinvccdf_deriv_left * (τ - interval.left)\n",
    "    elseif τ > interval.right\n",
    "        return abs(Γinvccdf_val_right + Γinvccdf_deriv_right * (τ - interval.right))\n",
    "    else\n",
    "        return Γinvccdf_cheb(τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_priorNormalized (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change definition and define negative log-PDF\n",
    "logpdf_original(ξ) = logpdf_original(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ\n",
    ")\n",
    "\n",
    "# Change definition and define negative log-PDF\n",
    "logpdf_priorNormalized(ξ) = logpdf_priorNormalized(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ, Φ=Γinvccdf_cheb_extd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the original posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_original.jld2\" θ_MAP z_MAP x_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "original_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "original_MAP[1:2:end] .= θ_MAP\n",
    "original_MAP[2:2:end] .= z_MAP\n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genrate random samples from the original prior \n",
    "\n",
    "original_prior = Array{Float64}(undef, 2*N, nr_chains)\n",
    "# Generate θ-samples from the gamma distribution\n",
    "θ_prior_samples = rand(Gamma(β,1), N, nr_chains)\n",
    "# Transform them into samples of the generalized gamma distribution \n",
    "θ_prior_samples = ϑ * θ_prior_samples.^(1/r)\n",
    "\n",
    "# Generate z-samples from the conditional Gaussian prior \n",
    "z_prior_samples = Array{Float64}(undef, N, nr_chains)\n",
    "# Loop over each chain and each sample to generate the normal samples\n",
    "for j in 1:nr_chains\n",
    "    for n in 1:N\n",
    "        # Standard deviation is sqrt(θ_prior_samples[i, j])\n",
    "        σ = sqrt(θ_prior_samples[n, j])\n",
    "        z_prior_samples[n, j] = rand(Normal(0, σ))\n",
    "    end\n",
    "    original_prior[1:2:end,j] .= θ_prior_samples[:,j]\n",
    "    original_prior[2:2:end,j] .= z_prior_samples[:,j]\n",
    "end\n",
    "\n",
    "\n",
    "## Genrate random samples from the standard normal prior \n",
    "priorNormalized_prior = Array{Float64}(undef, 2*N, nr_samples)\n",
    "τ_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "u_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains\n",
    "    priorNormalized_prior[1:2:end,j] .= τ_prior_samples[:,j]\n",
    "    priorNormalized_prior[2:2:end,j] .= u_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model3_mcmc_initPrior_AM_priorNormalized_samples10000000_thin1000_chains6.jld2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param_original = Array{Float64}(undef, 2*N, nr_chains)\n",
    "init_param_priorNormalized = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_MAP[:]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_MAP[:]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_prior[:,j]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the original posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:00\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works\n",
    "\n",
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains   \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_original[:,j], \n",
    "        logpdf_original, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_original = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_θ = [string(\"θ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_z = [string(\"z[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave θ and z names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_θ\n",
    "param_names[2:2:end] .= param_names_z\n",
    "\n",
    "# Create the Chains object\n",
    "chn_original = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_original chn_original wall_duration_original\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:13:33\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works \n",
    "\n",
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains \n",
    "    \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_priorNormalized[:,j], \n",
    "        logpdf_priorNormalized, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter?\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "    \n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_priorNormalized = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_τ = [string(\"τ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_u = [string(\"u[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave τ and u names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_τ\n",
    "param_names[2:2:end] .= param_names_u\n",
    "\n",
    "# Create the Chains object\n",
    "chn_priorNormalized = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_priorNormalized chn_priorNormalized wall_duration_priorNormalized\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_priorNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the model: $r=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 4 \n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Γinvccdf_cheb_extd (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interval = -5..5\n",
    "# Create an array of functions\n",
    "if r > 0 \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5*erfc(τ/sqrt(2)) ), interval)\n",
    "else \n",
    "    Γinvccdf_cheb = Fun(τ -> gammainvccdf(β, 1, 0.5 + 0.5*erf(τ/sqrt(2)) ), interval)\n",
    "end\n",
    "\n",
    "# Calculate the value and derivative at the boundaries\n",
    "Γinvccdf_val_left = Γinvccdf_cheb(interval.left)\n",
    "Γinvccdf_val_right = Γinvccdf_cheb(interval.right)\n",
    "\n",
    "Γinvccdf_deriv_left = ForwardDiff.derivative(Γinvccdf_cheb, interval.left)\n",
    "Γinvccdf_deriv_right = ForwardDiff.derivative(Γinvccdf_cheb, interval.right)\n",
    "\n",
    "# Define the extended function\n",
    "function Γinvccdf_cheb_extd(τ)\n",
    "    if τ < interval.left\n",
    "        return Γinvccdf_val_left + Γinvccdf_deriv_left * (τ - interval.left)\n",
    "    elseif τ > interval.right\n",
    "        return abs(Γinvccdf_val_right + Γinvccdf_deriv_right * (τ - interval.right))\n",
    "    else\n",
    "        return Γinvccdf_cheb(τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_priorNormalized (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change definition and define negative log-PDF\n",
    "logpdf_original(ξ) = logpdf_original(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ\n",
    ")\n",
    "\n",
    "# Change definition and define negative log-PDF\n",
    "logpdf_priorNormalized(ξ) = logpdf_priorNormalized(\n",
    "    ξ[1:2:end-1], ξ[2:2:end]; \n",
    "    F, y, r, β, ϑ, Φ=Γinvccdf_cheb_extd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the original posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_original.jld2\" θ_MAP z_MAP x_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "original_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "original_MAP[1:2:end] .= θ_MAP\n",
    "original_MAP[2:2:end] .= z_MAP\n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genrate random samples from the original prior \n",
    "\n",
    "original_prior = Array{Float64}(undef, 2*N, nr_chains)\n",
    "# Generate θ-samples from the gamma distribution\n",
    "θ_prior_samples = rand(Gamma(β,1), N, nr_chains)\n",
    "# Transform them into samples of the generalized gamma distribution \n",
    "θ_prior_samples = ϑ * θ_prior_samples.^(1/r)\n",
    "\n",
    "# Generate z-samples from the conditional Gaussian prior \n",
    "z_prior_samples = Array{Float64}(undef, N, nr_chains)\n",
    "# Loop over each chain and each sample to generate the normal samples\n",
    "for j in 1:nr_chains\n",
    "    for n in 1:N\n",
    "        # Standard deviation is sqrt(θ_prior_samples[i, j])\n",
    "        σ = sqrt(θ_prior_samples[n, j])\n",
    "        z_prior_samples[n, j] = rand(Normal(0, σ))\n",
    "    end\n",
    "    original_prior[1:2:end,j] .= θ_prior_samples[:,j]\n",
    "    original_prior[2:2:end,j] .= z_prior_samples[:,j]\n",
    "end\n",
    "\n",
    "\n",
    "## Genrate random samples from the standard normal prior \n",
    "priorNormalized_prior = Array{Float64}(undef, 2*N, nr_samples)\n",
    "τ_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "u_prior_samples = rand(Normal(0,1), N, nr_chains)\n",
    "\n",
    "for j in 1:nr_chains\n",
    "    priorNormalized_prior[1:2:end,j] .= τ_prior_samples[:,j]\n",
    "    priorNormalized_prior[2:2:end,j] .= u_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model4_mcmc_initPrior_AM_priorNormalized_samples10000000_thin1000_chains6.jld2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param_original = Array{Float64}(undef, 2*N, nr_chains)\n",
    "init_param_priorNormalized = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_MAP[:]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_MAP[:]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_prior[:,j]\n",
    "        init_param_priorNormalized[:,j] = priorNormalized_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "    # Prior-normalized model \n",
    "    filename_priorNormalized = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_AM_priorNormalized_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the original posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:28\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works\n",
    "\n",
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains   \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_original[:,j], \n",
    "        logpdf_original, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_original = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_θ = [string(\"θ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_z = [string(\"z[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave θ and z names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_θ\n",
    "param_names[2:2:end] .= param_names_z\n",
    "\n",
    "# Create the Chains object\n",
    "chn_original = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_original chn_original wall_duration_original\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the prior-normalized posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:14:25\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Produce samples from the target distribution.\n",
    "# Note: Only :asm = AdaptiveScalingMetropolis consistently works \n",
    "\n",
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "chn_values = zeros(Float64, nr_samples-burn_in, nr_parameters, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains \n",
    "    \n",
    "    # generate samples\n",
    "    chn_values[:,:,j] = adaptive_rwm(\n",
    "        init_param_priorNormalized[:,j], \n",
    "        logpdf_priorNormalized, \n",
    "        nr_samples_raw; # number of samples (add burn-in length) \n",
    "        algorithm=:asm, \n",
    "        b=burn_in_raw+1, # burn in length \n",
    "        thin=thin, # Thinning factor\n",
    "        progress=progress # show progress meter?\n",
    "    ).X'\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "    \n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_priorNormalized = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_τ = [string(\"τ[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "param_names_u = [string(\"u[\", i, \"]\") for i in 1:(nr_parameters÷2) ]\n",
    "\n",
    "# Interleave τ and u names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end] .= param_names_τ\n",
    "param_names[2:2:end] .= param_names_u\n",
    "\n",
    "# Create the Chains object\n",
    "chn_priorNormalized = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_priorNormalized chn_priorNormalized wall_duration_priorNormalized\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "#gelmandiag_multivariate(chn_priorNormalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
