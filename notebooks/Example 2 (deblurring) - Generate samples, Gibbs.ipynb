{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Gibbs sampling for original posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# To start this notebook with more than one thread run \"export JULIA_NUM_THREADS=4\" in the terminal \n",
    "# before starting the jupyter notebook\n",
    "\n",
    "# Ensure that Julia was launched with an appropriate number of threads\n",
    "println(Threads.nthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import module. \n",
    "using Revise\n",
    "using PriorNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "using AdaptiveMCMC # for using adaptive MCMC sampling\n",
    "using ApproxFun # for approximating gammainvccdf by a Chbychev interpolant  \n",
    "using CairoMakie # for plots \n",
    "using Dates # to measure computational time \n",
    "using Distributions\n",
    "using JLD2 # for saving and loading results\n",
    "using FlexiMaps # for log-range  \n",
    "using ForwardDiff # for AD\n",
    "using LinearAlgebra # to represent the identity matrix as \"I\" \n",
    "using Random # for generating random noise \n",
    "using StatsBase # for defining customized distributions \n",
    "using StatsFuns # for defining customized distributions \n",
    "using StatsPlots # for plotting \n",
    "using SparseArrays # for efficient storing of the forward operator \n",
    "using SpecialFunctions\n",
    "using Turing # for setting up the model and sampling \n",
    "using Optim # for ML and MAP estimation \n",
    "using Plots: Plots, plot, plot!, scatter, scatter!, savefig, surface, surface!\n",
    "using ProgressMeter # to show progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare arguments.  \n",
    "nr_chains = 6 # number of chains to sample \n",
    "nr_samples_raw = 10^3 # number of samples \n",
    "thin = 10^0 # Thinning factor; only every thin-th sample is stored\n",
    "init = \"MAP\" # Initialization option: \"MAP\", \"prior\"\n",
    "nr_samples = Int64( nr_samples_raw/thin )\n",
    "\n",
    "# Tests: \n",
    "# nr_samples_raw = 10^3, thin = 10^0: 3.6s & 2.5s\n",
    "# nr_samples_raw = 10^4, thin = 10^0: 25s & 48s\n",
    "# nr_samples_raw = 10^5, thin = 10^1: 664 & 466s\n",
    "# nr_samples_raw = 10^6, thin = 10^2: \n",
    "# nr_samples_raw = 10^7, thin = 10^3:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal deblurring problem: Define the data model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       "  1.0\n",
       " -2.4\n",
       "  2.8\n",
       " -0.6\n",
       " -0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model parameters \n",
    "σ² = 0.03^2 # noise variance \n",
    "kernel_width = 0.02 # width of the Gaussian kernel\n",
    "N_dense = 1_000 # number of points for the dense model\n",
    "N_coarse = 128 # number of points for the coarse model\n",
    "tt = [0.17, 0.39, 0.48, 0.73, 0.83] # Positions of the increments\n",
    "dx = [1, -2.4, 2.8, -0.6, -0.8] # Values of the increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the piecewise constant signal. \n",
    "function signal(t; tt=[0.17, 0.39, 0.48, 0.73, 0.83], \n",
    "    dx = [1, -2.4, 2.8, -0.6, -0.8])\n",
    "    x = 0\n",
    "    Ij = findall(x -> x < t, tt)\n",
    "    if !isempty(Ij)\n",
    "        x = sum(dx[Ij])\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Any}:\n",
       "  3.74278937539227e-18\n",
       "  5.744144243534786e-18\n",
       "  8.79393927412621e-18\n",
       "  1.3429811599511571e-17\n",
       "  2.0459022030414613e-17\n",
       "  3.1090554911693094e-17\n",
       "  4.713037498942281e-17\n",
       "  7.126926866908596e-17\n",
       "  1.0750603997755944e-16\n",
       "  1.6176805186960793e-16\n",
       "  2.428187113838113e-16\n",
       "  3.6358103971191115e-16\n",
       "  5.430629429581705e-16\n",
       "  ⋮\n",
       "  2.653109939010615e-16\n",
       "  1.693119370541826e-16\n",
       "  1.0509846120628357e-16\n",
       "  6.233097419208321e-17\n",
       "  3.399747075949146e-17\n",
       "  1.535468383152762e-17\n",
       "  3.2021048354653674e-18\n",
       " -4.614439835542763e-18\n",
       " -9.541335133345305e-18\n",
       " -1.2547439067780209e-17\n",
       " -1.4280276203172293e-17\n",
       " -1.5171704985465577e-17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the dense data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_dense = (1:N_dense) / N_dense \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_dense, N_dense, 1), N_dense, N_dense)\n",
    "T = S'\n",
    "F_dense = (6.4/N_dense) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Generate the dense step signal and observations \n",
    "x_dense = signal.(t_dense) # signal values \n",
    "y_dense = F_dense * x_dense # observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the coarse data model  \n",
    "\n",
    "# Generate the dense grid (we assume that the signal vanishes at t=0)\n",
    "t_coarse = (1:N_coarse) / N_coarse \n",
    "\n",
    "# Generate the dense forward operator \n",
    "S = reshape(repeat(t_coarse, N_coarse, 1), N_coarse, N_coarse)\n",
    "T = S'\n",
    "F_coarse = (6.4/N_coarse) * exp.(-1/(2*kernel_width^2) * (T.-S).^2) \n",
    "\n",
    "# Get the coarse grid and forward operator \n",
    "stride = 6 # use every stride-th point \n",
    "t_obs = t_coarse[1:stride:end]\n",
    "F_coarse = F_coarse[1:stride:end, :]\n",
    "\n",
    "# Find the nearest points in the dense grid\n",
    "m = length(t_obs)\n",
    "I_dense = zeros(Int, m)\n",
    "for j in 1:m\n",
    "    I_dense[j] = argmin(abs.(t_dense .- t_obs[j]))\n",
    "end\n",
    "     \n",
    "# Coarse data with added noise\n",
    "Random.seed!(123) # Setting the seed \n",
    "y_coarse = y_dense[I_dense] .+ sqrt(σ²)*randn(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invertible finite difference matrix\n",
    "aux = ones(N_coarse) * [-1.0, 1.0]'\n",
    "L = spzeros(Float64,N_coarse,N_coarse)\n",
    "L[2:end,:] = spdiagm(0=>-1*ones(N_coarse), 1=>ones(N_coarse))[1:N_coarse-1,1:N_coarse]\n",
    "L[1,1] = 1 \n",
    "\n",
    "# Change coordinates to promot sparsity in z = Lx\n",
    "FL = F_coarse / L # F_coarse * inv(L)\n",
    "\n",
    "# Whitening\n",
    "FL_w = (1/sqrt(σ²)) * FL\n",
    "y_w = (1/sqrt(σ²)) * y_coarse\n",
    "\n",
    "# Rename varables for simplicity \n",
    "F = FL_w \n",
    "y = y_w \n",
    "M, N = size(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model: $r=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select hyper-hyper-parameters \n",
    "model_nr = 4 \n",
    "\n",
    "# Parameter of of generalized gamma hyper-prior \n",
    "r_range = [ 1.0, .5, -.5, -1.0 ]; \n",
    "β_range = [ 1.501, 3.0918, 2.0165, 1.0017 ];\n",
    "ϑ_range = [ 5*10^(-2), 5.9323*10^(-3), 1.2583*10^(-3), 1.2308*10^(-4) ];\n",
    "\n",
    "# Select hyper-hyper-parameters \n",
    "r = r_range[model_nr] # power parameter \n",
    "β = β_range[model_nr] # shape parameter \n",
    "ϑ = ϑ_range[model_nr] # scale parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128-element Vector{Float64}:\n",
       " 4.997527572912228e-5\n",
       " 5.000659064280895e-5\n",
       " 5.003308921604457e-5\n",
       " 5.004673545790628e-5\n",
       " 5.004216155492188e-5\n",
       " 5.0019355238489405e-5\n",
       " 4.9983725274028313e-5\n",
       " 4.994324263582611e-5\n",
       " 4.990450263891553e-5\n",
       " 4.987031070624744e-5\n",
       " 4.984008721701541e-5\n",
       " 4.981213130486383e-5\n",
       " 4.9785761716268164e-5\n",
       " ⋮\n",
       " 4.96922514167353e-5\n",
       " 4.9692024722620115e-5\n",
       " 4.969199501004405e-5\n",
       " 4.969208013435234e-5\n",
       " 4.9692415605844076e-5\n",
       " 4.969307366154106e-5\n",
       " 4.9693858305752975e-5\n",
       " 4.9694375057087454e-5\n",
       " 4.9694302754215614e-5\n",
       " 4.969364991573615e-5\n",
       " 4.969278712728878e-5\n",
       " 4.969215803777444e-5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the original posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_original.jld2\" θ_MAP z_MAP x_MAP\n",
    "θ_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MAP estimates \n",
    "\n",
    "# MAP estimate of the original posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_original.jld2\" θ_MAP z_MAP x_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "original_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "original_MAP[1:2:end-1] .= θ_MAP\n",
    "original_MAP[2:2:end] .= z_MAP\n",
    "\n",
    "# MAP estimate of the prior-normalized posterior \n",
    "@load \"data/deblurring_model$(model_nr)_MAP_priorNormalized.jld2\" τ_MAP u_MAP\n",
    "# Initialize an empty vector to store the interleaved values\n",
    "priorNormalized_MAP = Vector{Float64}(undef, 2*N)\n",
    "# Interleave τ_MAP and u_MAP\n",
    "priorNormalized_MAP[1:2:end-1] .= τ_MAP;\n",
    "priorNormalized_MAP[2:2:end] .= u_MAP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genrate random samples from the original prior \n",
    "\n",
    "original_prior = Array{Float64}(undef, 2*N, nr_chains)\n",
    "# Generate θ-samples from the gamma distribution\n",
    "θ_prior_samples = rand(Gamma(β,1), N, nr_chains)\n",
    "# Transform them into samples of the generalized gamma distribution \n",
    "θ_prior_samples = ϑ * θ_prior_samples.^(1/r)\n",
    "\n",
    "# Generate z-samples from the conditional Gaussian prior \n",
    "z_prior_samples = Array{Float64}(undef, N, nr_chains)\n",
    "# Loop over each chain and each sample to generate the normal samples\n",
    "for j in 1:nr_chains\n",
    "    for n in 1:N\n",
    "        # Standard deviation is sqrt(θ_prior_samples[i, j])\n",
    "        σ = sqrt(θ_prior_samples[n, j])\n",
    "        z_prior_samples[n, j] = rand(Normal(0, σ))\n",
    "    end\n",
    "    original_prior[1:2:end,j] .= θ_prior_samples[:,j]\n",
    "    original_prior[2:2:end,j] .= z_prior_samples[:,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/deblurring_model4_mcmc_initMAP_Gibbs_original_samples1000_thin1_chains6.jld2\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an initialization for the MCMC chains \n",
    "init_param_original = Array{Float64}(undef, 2*N, nr_chains)\n",
    "\n",
    "# Use MAP estimate \n",
    "if init==\"MAP\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_MAP[:]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initMAP_Gibbs_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Use random prior samples \n",
    "elseif init==\"prior\"\n",
    "    # Select the initial set of parameters \n",
    "    for j in 1:nr_chains \n",
    "        init_param_original[:,j] = original_prior[:,j]\n",
    "    end\n",
    "\n",
    "    # Select the file names for saving the later MCMC results \n",
    "    # Original model \n",
    "    filename_original = joinpath(\n",
    "        \"data\", \n",
    "        \"deblurring_model$(model_nr)_mcmc_initPrior_Gibbs_original_samples$(nr_samples_raw)_thin$(thin)_chains$(nr_chains).jld2\"\n",
    "    )\n",
    "\n",
    "# Throw an error if none of the available options is provided\n",
    "else\n",
    "    error(\"Invalid initialization option provided: $init. Please choose either 'MAP' or 'prior'.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gibbs_sampler (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Gibbs sampling function\n",
    "function gibbs_sampler(θ_init, iterations, F, y, r, β, ϑ)\n",
    "    M, N = size(F) \n",
    "    Ft = transpose(F)\n",
    "    FtF = Ft*F\n",
    "    Fty = Ft*y\n",
    "    \n",
    "    # Initialize latent variables and parameters\n",
    "    z = randn(N)  # Initial guess for u\n",
    "    θ = θ_init\n",
    "\n",
    "    # Preallocate space to store samples\n",
    "    samples_z = zeros(iterations, N)\n",
    "    samples_θ = zeros(iterations, N)\n",
    "\n",
    "    for i in 1:iterations\n",
    "        \n",
    "        # Step 1: Sample z | y, θ\n",
    "        v1 = randn(M)\n",
    "        v2 = randn(N) \n",
    "        w = Ft*v1 + Diagonal( θ.^(-1/2) )*v2\n",
    "        C = FtF + Diagonal( θ.^(-1) )\n",
    "        rhs = Fty + w\n",
    "        z = C\\rhs\n",
    "\n",
    "        # Step 2: Sample θ | y, z\n",
    "        for n in 1:N\n",
    "            θ[n] = rand( InverseGamma(β+0.5, ϑ+0.5*(z[n]^2) ) )\n",
    "        end\n",
    "\n",
    "        # Store samples\n",
    "        samples_z[i, :] = z\n",
    "        samples_θ[i, :] = θ\n",
    "    end\n",
    "\n",
    "    return samples_θ, samples_z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:07\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "nr_parameters = 2*N\n",
    "Theta_init = zeros(Float64, N, nr_chains)\n",
    "Theta = zeros(Float64, nr_samples_raw, N, nr_chains)\n",
    "Z = zeros(Float64, nr_samples_raw, N, nr_chains)\n",
    "chn_values = zeros(Float64, nr_samples, 2*N, nr_chains)\n",
    "\n",
    "# Start the wall clock timer\n",
    "wall_start = now()\n",
    "\n",
    "# Use multiple threads. \n",
    "@showprogress Threads.@threads for j in 1:nr_chains   \n",
    "    \n",
    "    # Initilization \n",
    "    Theta_init[:,j] = init_param_original[1:2:end-1,j]\n",
    "    \n",
    "    # Generate samples\n",
    "    Theta[:,:,j], Z[:,:,j] = gibbs_sampler(\n",
    "        Theta_init[:,j], # initilization \n",
    "        nr_samples_raw, # number of samples \n",
    "        F, y, r, β, ϑ # data and prior model parameters \n",
    "    )\n",
    "    \n",
    "    # Store values \n",
    "    \n",
    "    chn_values[:,1:2:end-1,j] = Theta[1:thin:nr_samples_raw,:,j]\n",
    "    chn_values[:,2:2:end,j] = Z[1:thin:nr_samples_raw,:,j]\n",
    "    \n",
    "    # Clear memory after each chain\n",
    "    GC.gc()\n",
    "end\n",
    "\n",
    "# End the wall clock timer\n",
    "wall_end = now()\n",
    "wall_duration_ms = wall_end - wall_start\n",
    "# Convert wall duration to seconds\n",
    "wall_duration_original = Dates.value(wall_duration_ms) / 1000\n",
    "\n",
    "# Define the parameter names (θ[1], z[1], θ[2], z[2], ...)\n",
    "param_names_θ = [string(\"θ[\", i, \"]\") for i in 1:N ]\n",
    "param_names_z = [string(\"z[\", i, \"]\") for i in 1:N ]\n",
    "\n",
    "# Interleave θ and z names\n",
    "param_names = Vector{String}(undef, nr_parameters)\n",
    "param_names[1:2:end-1] .= param_names_θ\n",
    "param_names[2:2:end] .= param_names_z\n",
    "\n",
    "# Create the Chains object\n",
    "chn_original = Chains(chn_values, Symbol.(param_names));\n",
    "\n",
    "# Free the memory occupied by chn_values\n",
    "chn_values = nothing\n",
    "GC.gc()  # Optionally trigger garbage collection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Gelman, Rubin, and Brooks diagnostic (256 x 3), 5.824644507705167)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the MCMC chain and computational time\n",
    "@save filename_original chn_original wall_duration_original\n",
    "\n",
    "# Multivariate potential scale reduction factor (MPSRF) \n",
    "# To check convergence: Should be below 1.1\n",
    "\n",
    "gelmandiag_multivariate(chn_original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
